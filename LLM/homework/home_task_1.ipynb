{"cells":[{"cell_type":"markdown","metadata":{"id":"1-7pnpC3cnY0"},"source":["# Создание трансформера с нуля"]},{"cell_type":"markdown","metadata":{"id":"m2FDVspYdIl4"},"source":["**Цель домашнего задания**: создать собственный трансформер с нуля, реализуя все основные блоки самостоятельно."]},{"cell_type":"markdown","metadata":{"id":"5XmXqUMndW5f"},"source":["В теме №1 вы познакомились с архитектурой ***Трансформер*** и основными его составляющими. Давайте попробуем теперь их реализовать.\n","\n","Напомним еще раз, как выглядит модель типа трансформер:"]},{"cell_type":"markdown","metadata":{"id":"cSs3Tt71eQNb"},"source":["<img src='https://deeprevision.github.io/posts/001-transformer/transformer.png' align=\"center\" height=400, width=600>"]},{"cell_type":"markdown","metadata":{"id":"nALviN0PetMT"},"source":["### Multi-head attention блок"]},{"cell_type":"markdown","metadata":{"id":"DY7IDLBgqNe5"},"source":["Первый блок, который мы реализуем, является самой важной частью трансформера и называется Multi-head Attention."]},{"cell_type":"markdown","metadata":{"id":"5UK7DyYhqS3b"},"source":["Ниже представлен класс для реализации этого блока. Вам нужно дописать недостающие части кода, основываясь на теоретических знаниях.\n","\n","Напомним про центральную часть данного механизма: запрос, ключ, значение. **Запрос** — это информация, которую вы пытаетесь сопоставить. **Ключи** и **значения** — это сохраненная информация. Именно в этом и заключается суть механизма внимания: анализ различных частей данных и их объединение для получения синтезированного ответа на ваш запрос.\n","\n","<img src='https://miro.medium.com/v2/resize:fit:1400/1*dSwckeG028obZPWafgJrmw.png' align=\"center\" height=200, width=500>"]},{"cell_type":"markdown","metadata":{"id":"DEDMDRneswT0"},"source":["При обработке входящей последовательности необходимо учитывать несколько факторов.\n","\n","Во-первых, специальные токены заполнения, используемые для выравнивания всех последовательностей в батче до одного размера, должны игнорироваться нашей моделью.\n","\n","Во-вторых, в процессе обучения надо использовать маску, чтобы гарантировать, что модель на каждом временном шаге может видеть только информацию из прошлого."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fyRKAX_nQvOj"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import math\n","\n","\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, hidden_dim=256, num_heads=4):\n","        \"\"\"\n","        Инициализация MultiHeadAttention.\n","\n","        Аргументы:\n","            hidden_dim: Размерность входных данных.\n","            num_heads: Количество голов внимания, на которое делится вход.\n","        \"\"\"\n","        super(MultiHeadAttention, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.num_heads = num_heads\n","        assert hidden_dim % num_heads == 0, \"Размерность скрытого слоя должна быть делимой на количество голов\"\n","        self.Wv = nn.Linear(hidden_dim, hidden_dim, bias=False) # матрица значения (Value)\n","        self.Wk = # Ваш код здесь (матрица ключа (Key))\n","        self.Wq = # Ваш код здесь (матрица запроса (Query))\n","        self.Wo = # Ваш код здесь (выходной слой)\n","\n","\n","    def check_sdpa_inputs(self, x):\n","        \"\"\"\n","        Проверка входных данных для scaled_dot_product_attention.\n","\n","        Аргументы:\n","            x: Входной тензор.\n","        \"\"\"\n","        assert x.size(1) == self.num_heads, f\"Ожидаемый размер x должен быть ({-1, self.num_heads, -1, self.hidden_dim // self.num_heads}), получен {x.size()}\"\n","        assert x.size(3) == self.hidden_dim // self.num_heads\n","\n","\n","    def scaled_dot_product_attention(\n","            self,\n","            query,\n","            key,\n","            value,\n","            attention_mask=None,\n","            key_padding_mask=None):\n","        \"\"\"\n","        Scaled dot-product attention.\n","\n","        Аргументы:\n","            query: Тензор вида (batch_size, num_heads, query_sequence_length, hidden_dim//num_heads)\n","            key: Тензор вида (batch_size, num_heads, key_sequence_length, hidden_dim//num_heads)\n","            value: Тензор вида (batch_size, num_heads, key_sequence_length, hidden_dim//num_heads)\n","            attention_mask: Тензор вида (query_sequence_length, key_sequence_length)\n","            key_padding_mask: Тензор вида (sequence_length, key_sequence_length)\n","\n","        Возвращает:\n","            Тензор вида (batch_size, num_heads, sequence_length, hidden_dim)\n","        \"\"\"\n","        self.check_sdpa_inputs(query)\n","        self.check_sdpa_inputs(key)\n","        self.check_sdpa_inputs(value)\n","\n","\n","        d_k = query.size(-1)\n","        tgt_len, src_len = query.size(-2), key.size(-2)\n","\n","\n","        # логиты = (B, H, tgt_len, E) * (B, H, E, src_len) = (B, H, tgt_len, src_len)\n","        logits = # Ваш код здесь  (Вычисляем произведение query и key (пока без softmax))\n","\n","        # Маскирование\n","        if attention_mask is not None:\n","            if attention_mask.dim() == 2:\n","                assert attention_mask.size() == (tgt_len, src_len)\n","                attention_mask = attention_mask.unsqueeze(0)\n","                logits = logits + attention_mask\n","            else:\n","                raise ValueError(f\"Размер маски внимания {attention_mask.size()}\")\n","\n","\n","        # Маскирование ключа\n","        if key_padding_mask is not None:\n","            key_padding_mask = key_padding_mask.unsqueeze(1).unsqueeze(2)\n","            logits = logits + key_padding_mask\n","\n","\n","        attention = # Ваш код здесь (softmax для logits)\n","        output = # Ваш код здесь (Умножаем на матрицу value)\n","\n","        return output, attention\n","\n","\n","    def split_into_heads(self, x, num_heads):\n","        \"\"\"\n","        Разделение тензора на несколько голов внимания.\n","\n","        Аргументы:\n","            x: Входной тензор.\n","            num_heads: Количество голов внимания.\n","\n","        Возвращает:\n","            Тензор с размерностью (batch_size, num_heads, seq_length, hidden_dim // num_heads)\n","        \"\"\"\n","        batch_size, seq_length, hidden_dim = x.size()\n","        x = x.view(batch_size, seq_length, num_heads, hidden_dim // num_heads)\n","\n","        return x.transpose(1, 2) # Финальная размерность будет (batch_size, num_heads, seq_length, hidden_dim // num_heads)\n","\n","    def combine_heads(self, x):\n","        \"\"\"\n","        Объединение голов внимания в один тензор.\n","\n","        Аргументы:\n","            x: Тензор с размерностью (batch_size, num_heads, seq_length, head_hidden_dim)\n","\n","        Возвращает:\n","            Тензор с размерностью (batch_size, seq_length, num_heads * head_hidden_dim)\n","        \"\"\"\n","        batch_size, num_heads, seq_length, head_hidden_dim = x.size()\n","        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, num_heads * head_hidden_dim)\n","\n","\n","    def forward(\n","            self,\n","            q,\n","            k,\n","            v,\n","            attention_mask=None,\n","            key_padding_mask=None):\n","        \"\"\"\n","        Прямой проход через Multi-Head Attention.\n","\n","        Аргументы:\n","            q: Тензор вида (batch_size, query_sequence_length, hidden_dim)\n","            k: Тензор вида (batch_size, key_sequence_length, hidden_dim)\n","            v: Тензор вида (batch_size, key_sequence_length, hidden_dim)\n","            attention_mask: Тензор вида (query_sequence_length, key_sequence_length)\n","            key_padding_mask: Тензор вида (sequence_length, key_sequence_length)\n","\n","        Возвращает:\n","            Тензор вида (batch_size, seq_len, n_dim)\n","        \"\"\"\n","        q = self.Wq(q)\n","        k = self.Wk(k)\n","        v = self.Wv(v)\n","\n","        q = # Ваш код здесь (Разделяем на головы)\n","        k = # Ваш код здесь (Разделяем на головы)\n","        v = # Ваш код здесь (Разделяем на головы)\n","\n","        attn_values, attn_weights  = self.scaled_dot_product_attention(\n","            query=q,\n","            key=k,\n","            value=v,\n","            attention_mask=attention_mask,\n","            key_padding_mask=key_padding_mask,\n","        )\n","        grouped = self.combine_heads(attn_values)\n","        output = self.Wo(grouped)\n","\n","        self.attention_weigths = attn_weights\n","\n","        return output"]},{"cell_type":"markdown","metadata":{"id":"Ho-DghwkvGu9"},"source":["### Позиционное кодирование"]},{"cell_type":"markdown","metadata":{"id":"DTXx3vYNvJKW"},"source":["При получении и обработке входных данных трансформер не имеет понятия о порядке слов, так как рассматривает последовательность целиком, в отличие от рекуррентных нейронных сетей (RNN). Поэтому нам необходимо добавить указание на временной порядок, чтобы трансформер мог изучать зависимости.\n","\n","<img src='https://i.sstatic.net/67ADh.png' align=\"center\" height=80, width=300>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jNhK6OqDTBqE"},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","\n","    def __init__(self, d_model, dropout=0.1, max_len=5000):\n","        \"\"\"\n","        Инициализация PositionalEncoding.\n","\n","        Аргументы:\n","            d_model: Размерность модели.\n","            dropout: Вероятность dropout.\n","            max_len: Максимальная длина последовательности.\n","        \"\"\"\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","\n","        # Применение синусоидальной функции к чётным индексам\n","        pe[:, 0::2] = # Ваш код здесь\n","\n","        # Применение косинусоидальной функции к нечётным индексам\n","        pe[:, 1::2] = # Ваш код здесь\n","\n","        pe = pe.unsqueeze(0)\n","\n","        # Регистрация 'pe' как буфера, чтобы он не обучался\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Прямой проход через PositionalEncoding.\n","\n","        Аргументы:\n","            x: Тензор вида ``[batch_size, seq_len, embedding_dim]``\n","\n","        Возвращает:\n","            Тензор с добавленным позиционным кодированием.\n","        \"\"\"\n","        x = x + self.pe[:, :x.size(1), :]\n","        return self.dropout(x)\n"]},{"cell_type":"markdown","metadata":{"id":"36adjejmwwQN"},"source":["### Feed-forward слой"]},{"cell_type":"markdown","metadata":{"id":"ioLuO4YFw0qz"},"source":["Последний ингредиент: слой прямого распространения."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7BOS2SNzTXpX"},"outputs":[],"source":["class PositionWiseFeedForward(nn.Module):\n","    def __init__(self, d_model: int, d_ff: int):\n","        \"\"\"\n","        Инициализация PositionWiseFeedForward.\n","\n","        Аргументы:\n","            d_model: Размерность модели.\n","            d_ff: Размерность внутреннего слоя в feed-forward сети.\n","        \"\"\"\n","        super(PositionWiseFeedForward, self).__init__()\n","        self.fc1 = nn.Linear(d_model, d_ff)\n","        self.fc2 = nn.Linear(d_ff, d_model)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Прямой проход через PositionWiseFeedForward.\n","\n","        Аргументы:\n","            x: Входной тензор вида ``[batch_size, seq_len, d_model]``\n","\n","        Возвращает:\n","            Тензор после применения feed-forward сети, форма ``[batch_size, seq_len, d_model]``\n","        \"\"\"\n","        # Применение первого линейного слоя и функции активации ReLU\n","        x = self.relu(self.fc1(x))\n","\n","        # Применение второго линейного слоя\n","        return self.fc2(x)\n"]},{"cell_type":"markdown","metadata":{"id":"sLnpORxzxIyh"},"source":["### Encoder-блок\n","\n","Теперь собираем все вместе в единый энкодер-блок!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gz-Q7uq2TYiA"},"outputs":[],"source":["class EncoderBlock(nn.Module):\n","    def __init__(self, n_dim: int, dropout: float, n_heads: int):\n","        \"\"\"\n","        Инициализация EncoderBlock.\n","\n","        Аргументы:\n","            n_dim: Размерность входного и выходного тензоров.\n","            dropout: Вероятность dropout.\n","            n_heads: Количество голов в multi-head attention.\n","        \"\"\"\n","        super(EncoderBlock, self).__init__()\n","        self.mha = MultiHeadAttention(hidden_dim=n_dim, num_heads=n_heads)\n","        self.norm1 = nn.LayerNorm(n_dim)\n","        self.ff = PositionWiseFeedForward(n_dim, n_dim)\n","        self.norm2 = nn.LayerNorm(n_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, src_padding_mask=None):\n","        \"\"\"\n","        Прямой проход через EncoderBlock.\n","\n","        Аргументы:\n","            x: Входной тензор вида ``[batch_size, seq_len, n_dim]``.\n","            src_padding_mask: Маска заполнения размерности ``[batch_size, seq_len]`` или ``[batch_size, 1, 1, seq_len]``.\n","\n","        Возвращает:\n","            Тензор вида ``[batch_size, seq_len, n_dim]``.\n","        \"\"\"\n","        assert x.ndim == 3, \"Ожидается, что вход будет 3-мерным, получено {}\".format(x.ndim)\n","\n","        # Применение многоуровневого механизма внимания (Multi-Head Attention)\n","        att_output = self.mha(x, x, x, key_padding_mask=src_padding_mask)\n","\n","        # Применение dropout и layer normalization после внимания\n","        x = x + self.dropout(self.norm1(att_output))\n","\n","        # Применение позиционно-зависимой функции активации (Position-Wise Feed-Forward)\n","        ff_output = self.ff(x)\n","\n","        # Применение layer normalization после функции активации\n","        output = x + self.norm2(ff_output)\n","\n","        return output"]},{"cell_type":"markdown","metadata":{"id":"grL5tbGpxRO0"},"source":["### Encoder\n","\n","И собираем теперь несколько энкодер-блоков вместе."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k42PZgONTmp_"},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(\n","            self,\n","            vocab_size: int,\n","            n_dim: int,\n","            dropout: float,\n","            n_encoder_blocks: int,\n","            n_heads: int):\n","        \"\"\"\n","        Инициализация Encoder.\n","\n","        Аргументы:\n","            vocab_size: Размер словаря.\n","            n_dim: Размерность эмбеддингов.\n","            dropout: Вероятность dropout.\n","            n_encoder_blocks: Количество блоков энкодера.\n","            n_heads: Количество голов в multi-head attention.\n","        \"\"\"\n","        super(Encoder, self).__init__()\n","        self.n_dim = n_dim\n","\n","        # Слой эмбеддингов\n","        self.embedding = nn.Embedding(\n","            num_embeddings=vocab_size,\n","            embedding_dim=n_dim\n","        )\n","\n","        # Позиционное кодирование\n","        self.positional_encoding = PositionalEncoding(\n","            d_model=n_dim,\n","            dropout=dropout\n","        )\n","\n","        # Список блоков энкодера\n","        self.encoder_blocks = nn.ModuleList([\n","            EncoderBlock(n_dim, dropout, n_heads) for _ in range(n_encoder_blocks)\n","        ])\n","\n","\n","    def forward(self, x, padding_mask=None):\n","        \"\"\"\n","        Прямой проход через Encoder.\n","\n","        Аргументы:\n","            x: Входной тензор вида ``[batch_size, seq_len]``.\n","            padding_mask: Маска заполнения размерности ``[batch_size, seq_len]``.\n","\n","        Возвращает:\n","            Тензор вида ``[batch_size, seq_len, n_dim]``.\n","        \"\"\"\n","        # Преобразование входных индексов в эмбеддинги и масштабирование\n","        x = self.embedding(x) * math.sqrt(self.n_dim)\n","\n","        # Применение позиционного кодирования\n","        x = self.positional_encoding(x)\n","\n","        # Пропуск через каждый блок энкодера\n","        for block in self.encoder_blocks:\n","            x = block(x=x, src_padding_mask=padding_mask)\n","\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"WnVFbK5Vy92_"},"source":["### Decoder-блок и Decoder\n","\n","Займемся теперь декодером. Здесь используются сразу 2 вида внимания. Первое - это так называемое маскированное многоголовое внимание (Masked Multi-Head Attention). Помните, что мы говорили ранее о маскировании? Именно здесь это и происходит. Мы будем использовать параметр attention_mask нашего модуля многоголового внимания. Второй тип внимания называется перекрёстным вниманием (cross-attention). Он использует запрос декодера для сопоставления с ключами и значениями энкодера. Важно отметить, что во время обучения их длины могут различаться, поэтому важно чётко определить ожидаемые размерности входных данных."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OlgYcnqeVgVa"},"outputs":[],"source":["class DecoderBlock(nn.Module):\n","    def __init__(self, n_dim: int, dropout: float, n_heads: int):\n","        \"\"\"\n","        Инициализация DecoderBlock.\n","\n","        Аргументы:\n","            n_dim: Размерность модели.\n","            dropout: Вероятность dropout.\n","            n_heads: Количество голов в multi-head attention.\n","        \"\"\"\n","        super(DecoderBlock, self).__init__()\n","\n","        # Первый Multi-Head Attention имеет маску для предотвращения заглядывания в будущее\n","        self.self_attention = MultiHeadAttention(hidden_dim=n_dim, num_heads=n_heads)\n","        self.norm1 = nn.LayerNorm(n_dim)\n","\n","        # Второй Multi-Head Attention принимает входы от энкодера\n","        self.cross_attention = MultiHeadAttention(hidden_dim=n_dim, num_heads=n_heads)\n","        self.norm2 = nn.LayerNorm(n_dim)\n","\n","        self.ff = PositionWiseFeedForward(n_dim, n_dim)\n","        self.norm3 = nn.LayerNorm(n_dim)\n","\n","    def forward(self, tgt, memory, tgt_mask=None, tgt_padding_mask=None, memory_padding_mask=None):\n","        \"\"\"\n","        Прямой проход через DecoderBlock.\n","\n","        Аргументы:\n","            tgt: Тензор таргетов вида ``[batch_size, tgt_len, n_dim]``\n","            memory: Тензор памяти из энкодера вида ``[batch_size, src_len, n_dim]``\n","            tgt_mask: Маска таргетов размерности ``[batch_size, tgt_len, tgt_len]``\n","            tgt_padding_mask: Маска заполнения таргетов размерности ``[batch_size, tgt_len]``\n","            memory_padding_mask: Маска заполнения памяти размерности ``[batch_size, src_len]``\n","\n","        Возвращает:\n","            Тензор вида ``[batch_size, tgt_len, n_dim]``\n","        \"\"\"\n","        # Применение self-attention с маской\n","        masked_att_output = self.self_attention(\n","            q=tgt, k=tgt, v=tgt, attention_mask=tgt_mask, key_padding_mask=tgt_padding_mask)\n","        x1 = tgt + self.norm1(masked_att_output)\n","\n","        # Применение cross-attention с query и key из энкодера\n","        cross_att_output = # Ваш код здесь\n","        x2 = x1 + self.norm2(cross_att_output)\n","\n","        # Применение position-wise feed-forward\n","        ff_output = self.ff(x2)\n","        output = x2 + self.norm3(ff_output)\n","\n","        return output\n","\n","class Decoder(nn.Module):\n","    def __init__(\n","        self,\n","        vocab_size: int,\n","        n_dim: int,\n","        dropout: float,\n","        n_decoder_blocks: int,\n","        n_heads: int):\n","        \"\"\"\n","        Инициализация Decoder.\n","\n","        Аргументы:\n","            vocab_size: Размер словаря.\n","            n_dim: Размерность модели.\n","            dropout: Вероятность dropout.\n","            n_decoder_blocks: Количество блоков декодера.\n","            n_heads: Количество голов в multi-head attention.\n","        \"\"\"\n","        super(Decoder, self).__init__()\n","\n","        self.embedding = nn.Embedding(\n","            num_embeddings=vocab_size,\n","            embedding_dim=n_dim,\n","            padding_idx=0\n","        )\n","        self.positional_encoding = PositionalEncoding(\n","            d_model=n_dim,\n","            dropout=dropout\n","        )\n","\n","        self.decoder_blocks = nn.ModuleList([\n","            DecoderBlock(n_dim, dropout, n_heads) for _ in range(n_decoder_blocks)\n","        ])\n","\n","    def forward(self, tgt, memory, tgt_mask=None, tgt_padding_mask=None, memory_padding_mask=None):\n","        \"\"\"\n","        Прямой проход через Decoder.\n","\n","        Аргументы:\n","            tgt: Тензор таргетов вида ``[batch_size, tgt_len, n_dim]``\n","            memory: Тензор памяти из энкодера вида ``[batch_size, src_len, n_dim]``\n","            tgt_mask: Маска таргетов размерности ``[batch_size, tgt_len, tgt_len]``\n","            tgt_padding_mask: Маска заполнения таргетов размерности ``[batch_size, tgt_len]``\n","            memory_padding_mask: Маска заполнения памяти размерности ``[batch_size, src_len]``\n","\n","        Возвращает:\n","            Тензор вида ``[batch_size, tgt_len, n_dim]``\n","        \"\"\"\n","        x = self.embedding(tgt)\n","        x = self.positional_encoding(x)\n","\n","        for block in self.decoder_blocks:\n","            x = block(\n","                x,\n","                memory,\n","                tgt_mask=tgt_mask,\n","                tgt_padding_mask=tgt_padding_mask,\n","                memory_padding_mask=memory_padding_mask)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"OQfBasFpG-si"},"source":["### Трансформер\n","\n","Теперь соединяем энкодер и декодер вместе и получаем полноценный трансформер!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ti_GO_PWn3t"},"outputs":[],"source":["class Transformer(nn.Module):\n","    def __init__(self, **kwargs):\n","        super(Transformer, self).__init__()\n","\n","        # Вывод и установка параметров модели из kwargs\n","        for k, v in kwargs.items():\n","            print(f\" * {k}={v}\")\n","\n","        self.vocab_size = kwargs.get('vocab_size')          # Размер словаря\n","        self.model_dim = kwargs.get('model_dim')            # Размерность модели\n","        self.dropout = kwargs.get('dropout')                # Вероятность dropout\n","        self.n_encoder_layers = kwargs.get('n_encoder_layers')  # Количество слоёв в энкодере\n","        self.n_decoder_layers = kwargs.get('n_decoder_layers')  # Количество слоёв в декодере\n","        self.n_heads = kwargs.get('n_heads')                # Количество голов в multi-head attention\n","        self.batch_size = kwargs.get('batch_size')          # Размер батча\n","        self.PAD_IDX = kwargs.get('pad_idx', 0)             # Индекс заполнения (PAD)\n","\n","        # Инициализация кодировщика, декодировщика и окончательного полносвязного слоя\n","        self.encoder = # Ваш код здесь\n","        self.decoder = # Ваш код здесь\n","        self.fc = # Ваш код здесь\n","\n","\n","    @staticmethod\n","    def generate_square_subsequent_mask(size: int):\n","        \"\"\"\n","        Генерация треугольной маски.\n","\n","        Аргументы:\n","            size: int, размер маски\n","\n","        Возвращает:\n","            torch.Tensor, треугольная маска\n","        \"\"\"\n","        mask = (1 - torch.triu(torch.ones(size, size), diagonal=1)).bool()\n","        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","        return mask\n","\n","\n","    def encode(\n","            self,\n","            x: torch.Tensor,\n","        ) -> torch.Tensor:\n","        \"\"\"\n","        Кодирование входных последовательностей с использованием модуля Encoder.\n","\n","        Аргументы:\n","            x: torch.Tensor, входной тензор вида (batch_size, seq_len)\n","\n","        Возвращает:\n","            torch.Tensor, закодированный выходной тензор вида (batch_size, seq_len, model_dim)\n","        \"\"\"\n","\n","        mask = (x == self.PAD_IDX).float()\n","        encoder_padding_mask = mask.masked_fill(mask == 1, float('-inf'))\n","\n","        encoder_output = self.encoder(\n","            x,\n","            padding_mask=encoder_padding_mask\n","        )\n","\n","        return encoder_output, encoder_padding_mask\n","\n","\n","    def decode(\n","            self,\n","            tgt: torch.Tensor,\n","            memory: torch.Tensor,\n","            memory_padding_mask=None\n","        ) -> torch.Tensor:\n","        \"\"\"\n","        Декодирование целевых последовательностей с использованием модуля Decoder.\n","\n","        Аргументы:\n","            tgt: torch.Tensor, целевой тензор вида (batch_size, tgt_len)\n","            memory: torch.Tensor, тензор памяти от Encoder вида (batch_size, src_len, model_dim)\n","            memory_padding_mask: torch.Tensor, опционально, маска заполнения для тензора памяти\n","\n","        Возвращает:\n","            torch.Tensor, декодированный выходной тензор вида (batch_size, tgt_len, vocab_size)\n","        \"\"\"\n","\n","        mask = (tgt == self.PAD_IDX).float()\n","        tgt_padding_mask = mask.masked_fill(mask == 1, float('-inf'))\n","\n","        decoder_output = self.decoder(\n","            tgt=tgt,\n","            memory=memory,\n","            tgt_mask=self.generate_square_subsequent_mask(tgt.size(1)),\n","            tgt_padding_mask=tgt_padding_mask,\n","            memory_padding_mask=memory_padding_mask,\n","        )\n","        output = self.fc(decoder_output)  # вид (B, L, C)\n","        return output\n","\n","\n","    def forward(\n","            self,\n","            x: torch.Tensor,\n","            y: torch.Tensor,\n","        ) -> torch.Tensor:\n","        \"\"\"\n","        Прямой проход модели Transformer.\n","\n","        Аргументы:\n","            x: torch.Tensor, входной тензор вида (batch_size, src_len)\n","            y: torch.Tensor, целевой тензор вида (batch_size, tgt_len)\n","\n","        Возвращает:\n","            torch.Tensor, декодированный выходной тензор вида (batch_size, tgt_len, vocab_size)\n","        \"\"\"\n","\n","        # Форма выхода Encoder (B, S, E)\n","        encoder_output, encoder_padding_mask = self.encode(x)\n","\n","        # Форма выхода Decoder (B, L, C)\n","        decoder_output = self.decode(\n","            tgt=y,\n","            memory=encoder_output,\n","            memory_padding_mask=encoder_padding_mask\n","        )\n","\n","        return decoder_output"]},{"cell_type":"markdown","metadata":{"id":"7zgIXLwLH6ns"},"source":["### Задача\n","\n","Отлично! Мы собрали трансформер. Надо теперь придумать какую-нибудь задачу. Давайте попробубуем обучить трансформер переворачивать слова. То есть для каждой входной строки он должен выдавать ее в обратном порядке.\n","\n","Но зачем использовать целый трансформер для перестановки слов? В python это можно сделать одной строчкой кода.\n","\n","Цель — посмотреть, работает ли механизм внимания трансформера. Мы ожидаем увидеть, что веса внимания будут перемещаться справа налево при задании входной последовательности. Если это так, это означает, что наш трансформер выучил очень простую грамматику, которая просто читается справа налево, и может обобщать ее до более сложных грамматик при выполнении перевода с реального языка."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5m2WI9j4YBGQ"},"outputs":[],"source":["import numpy as np\n","import torch\n","from torch.utils.data import Dataset\n","\n","\n","np.random.seed(0) # Для воспроизводимости\n","\n","def generate_random_string():\n","    \"\"\"\n","    Генерирует случайную строку длиной от 10 до 20 символов.\n","    Возвращает:\n","        str: случайная строка, состоящая из маленьких латинских букв.\n","    \"\"\"\n","    len = np.random.randint(10, 20)\n","    return \"\".join([chr(x) for x in np.random.randint(97, 97+26, len)])\n","\n","class ReverseDataset(Dataset):\n","    def __init__(self, n_samples, pad_idx, sos_idx, eos_idx):\n","        \"\"\"\n","        Инициализация класса ReverseDataset.\n","\n","        Аргументы:\n","            n_samples (int): количество образцов в наборе данных.\n","            pad_idx (int): индекс заполнения (PAD).\n","            sos_idx (int): индекс начала последовательности (SOS).\n","            eos_idx (int): индекс конца последовательности (EOS).\n","        \"\"\"\n","        super(ReverseDataset, self).__init__()\n","        self.pad_idx = pad_idx\n","        self.sos_idx = sos_idx\n","        self.eos_idx = eos_idx\n","        self.values = [generate_random_string() for _ in range(n_samples)]\n","        self.labels = [x[::-1] for x in self.values]  # строки, обращённые задом наперёд\n","\n","    def __len__(self):\n","        \"\"\"\n","        Возвращает количество образцов в наборе данных.\n","\n","        Возвращает:\n","            int: количество образцов.\n","        \"\"\"\n","        return len(self.values)\n","\n","    def __getitem__(self, index):\n","        \"\"\"\n","        Возвращает образец из набора данных по заданному индексу.\n","\n","        Аргументы:\n","            index (int): индекс образца.\n","\n","        Возвращает:\n","            tuple: кортеж из двух тензоров - входной строки и соответствующей ей обратной строки.\n","        \"\"\"\n","        return self.text_transform(self.values[index].rstrip(\"\\n\")), \\\n","               self.text_transform(self.labels[index].rstrip(\"\\n\"))\n","\n","    def text_transform(self, x):\n","        \"\"\"\n","        Преобразует строку в тензор, добавляя индексы SOS и EOS.\n","\n","        Аргументы:\n","            x (str): входная строка.\n","\n","        Возвращает:\n","            torch.Tensor: тензор, представляющий строку с добавленными индексами SOS и EOS.\n","        \"\"\"\n","        return torch.tensor([self.sos_idx] + [ord(z) - 97 + 3 for z in x] + [self.eos_idx])\n"]},{"cell_type":"markdown","metadata":{"id":"03Zun8ZpJSRv"},"source":["Датасет готов, осталось теперь написать цикл обучения и цикл валидации. Не забудьте в цикле обучения прописать шаг оптимизатор и обратный проход."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UEudqeNZZUvP"},"outputs":[],"source":["PAD_IDX = 0 # Токен заполения\n","SOS_IDX = 1 # Токен начала предложения\n","EOS_IDX = 2 # Токен конца предложения\n","\n","def train(model, optimizer, loader, loss_fn, epoch):\n","    \"\"\"\n","    Обучение модели на одной эпохе.\n","\n","    Аргументы:\n","        model: Обучаемая модель.\n","        optimizer: Оптимизатор, используемый для обновления весов модели.\n","        loader: Даталоадер для тренировочного набора данных.\n","        loss_fn: Функция потерь.\n","        epoch: Номер текущей эпохи.\n","\n","    Возвращает:\n","        tuple: Средняя потеря, средняя точность, история потерь и история точности за эпоху.\n","    \"\"\"\n","    model.train()\n","    losses = 0\n","    acc = 0\n","    history_loss = []\n","    history_acc = []\n","\n","    with tqdm(loader, position=0, leave=True) as tepoch:\n","        for x, y in tepoch:\n","            tepoch.set_description(f\"Эпоха {epoch}\")\n","\n","            # Ваш код здесь\n","            logits = model(x, y[:, :-1])\n","            loss = loss_fn(logits.contiguous().view(-1, model.vocab_size), y[:, 1:].contiguous().view(-1))\n","            # Ваш код здесь\n","            # Ваш код здесь\n","            losses += loss.item()\n","\n","            preds = logits.argmax(dim=-1)\n","            masked_pred = preds * (y[:, 1:] != PAD_IDX)\n","            accuracy = (masked_pred == y[:, 1:]).float().mean()\n","            acc += accuracy.item()\n","\n","            history_loss.append(loss.item())\n","            history_acc.append(accuracy.item())\n","            tepoch.set_postfix(loss=loss.item(), accuracy=100. * accuracy.item())\n","\n","    return losses / len(list(loader)), acc / len(list(loader)), history_loss, history_acc\n","\n","\n","def evaluate(model, loader, loss_fn):\n","    \"\"\"\n","    Оценка модели на валидационном или тестовом наборе данных.\n","\n","    Аргументы:\n","        model: Модель для оценки.\n","        loader: Даталоадер для валидационного или тестового набора данных.\n","        loss_fn: Функция потерь.\n","\n","    Возвращает:\n","        tuple: Средняя потеря, средняя точность, история потерь и история точности на всем наборе данных.\n","    \"\"\"\n","    model.eval()\n","    losses = 0\n","    acc = 0\n","    history_loss = []\n","    history_acc = []\n","\n","    for x, y in tqdm(loader, position=0, leave=True):\n","        logits = model(x, y[:, :-1])\n","        loss = loss_fn(logits.contiguous().view(-1, model.vocab_size), y[:, 1:].contiguous().view(-1))\n","        losses += loss.item()\n","\n","        preds = logits.argmax(dim=-1)\n","        masked_pred = preds * (y[:, 1:] != PAD_IDX)\n","        accuracy = (masked_pred == y[:, 1:]).float().mean()\n","        acc += accuracy.item()\n","\n","        history_loss.append(loss.item())\n","        history_acc.append(accuracy.item())\n","\n","    return losses / len(list(loader)), acc / len(list(loader)), history_loss, history_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d6rGnqiVZwIS"},"outputs":[],"source":["import torch\n","import time\n","import torch.nn as nn\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from tqdm import tqdm\n","from torch.utils.data import DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","from mpl_toolkits.axes_grid1 import ImageGrid\n","\n","\n","def collate_fn(batch):\n","    \"\"\"\n","    Эта функция добавляет заполнители (PAD_IDX) к входным данным, чтобы все последовательности в батче имели одинаковую длину.\n","    \"\"\"\n","    src_batch, tgt_batch = [], []\n","    for src_sample, tgt_sample in batch:\n","        src_batch.append(src_sample)\n","        tgt_batch.append(tgt_sample)\n","\n","    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first=True)\n","    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX, batch_first=True)\n","    return src_batch, tgt_batch\n","\n","# Гиперпараметры модели (Можно попробовать другие и сравнить качество)\n","args = {\n","    'vocab_size': 128,\n","    'model_dim': 128,\n","    'dropout': 0.1,\n","    'n_encoder_layers': 1,\n","    'n_decoder_layers': 1,\n","    'n_heads': 4\n","}\n","\n","# Определение модели\n","model = Transformer(**args)\n","\n","# Создание наборов данных\n","train_iter = ReverseDataset(50000, pad_idx=PAD_IDX, sos_idx=SOS_IDX, eos_idx=EOS_IDX) # Размер датасетов можно менять\n","eval_iter = ReverseDataset(10000, pad_idx=PAD_IDX, sos_idx=SOS_IDX, eos_idx=EOS_IDX)\n","dataloader_train = DataLoader(train_iter, batch_size=256, collate_fn=collate_fn)\n","dataloader_val = DataLoader(eval_iter, batch_size=256, collate_fn=collate_fn)\n","\n","# Инициализация параметров модели\n","for p in model.parameters():\n","    if p.dim() > 1:\n","        nn.init.xavier_uniform_(p)\n","\n","# Определение функции потерь: мы игнорируем логиты, которые являются токенами заполнителей\n","loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n","\n","# Сохранение истории в словарь\n","history = {\n","    'train_loss': [],\n","    'eval_loss': [],\n","    'train_acc': [],\n","    'eval_acc': []\n","}\n","\n","# Основной цикл\n","for epoch in range(1, 4):\n","    start_time = time.time()\n","    train_loss, train_acc, hist_loss, hist_acc = train(model, optimizer, dataloader_train, loss_fn, epoch)\n","    history['train_loss'] += hist_loss\n","    history['train_acc'] += hist_acc\n","    end_time = time.time()\n","    val_loss, val_acc, hist_loss, hist_acc = evaluate(model, dataloader_val, loss_fn)\n","    history['eval_loss'] += hist_loss\n","    history['eval_acc'] += hist_acc\n","    print((f\"Эпоха: {epoch}, Loss при обучении: {train_loss:.3f}, Точность при обучении: {train_acc:.3f}, Loss при валидации: {val_loss:.3f}, Точность при валидации: {val_acc:.3f} \"f\"Время эпохи = {(end_time - start_time):.3f}с\"))"]},{"cell_type":"markdown","metadata":{"id":"PEFzUJbkJm6Z"},"source":["Что можно сказать о поведении функции потерь и точности?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DmafGfe8yAz0"},"outputs":[],"source":["# @markdown ---\n","\n","Функция потерь = \"растет\" # @param [\"падает\", \"растет\"]\n","Точность = \"растет\" # @param [\"падает\", \"растет\"]\n","\n","# @markdown ---\n"]},{"cell_type":"markdown","metadata":{"id":"PlSGPSpzJeFj"},"source":["Отрисуйте теперь тепловую карту весов из первого блока декодера."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WlRHrVTVaQFr"},"outputs":[],"source":["fig = plt.figure(figsize=(10., 10.))\n","# Получение весов внимания из первого блока декодера\n","images = # Ваш код здесь\n","# Создание сетки из 2x2 подграфиков\n","grid = ImageGrid(fig, 111,\n","                 nrows_ncols=(2, 2),  # создание сетки 2x2 осей\n","                 axes_pad=0.1,  # отступ между осями в дюймах\n","                )\n","\n","# Отображение изображений на подграфиках\n","for ax, im in zip(grid, images):\n","    ax.imshow(im)\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"3fPqKS66Jl6g"},"source":["Что можно пронаблюдать?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7M9onPz6y_zp"},"outputs":[],"source":["Ваш ответ = \"\" # @param {type:\"string\"}"]},{"cell_type":"markdown","metadata":{"id":"KnccWM7vKHcf"},"source":["Давайте теперь протестируем нашу модель."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wb0bnnyDaX54"},"outputs":[],"source":["class Translator(nn.Module):\n","    def __init__(self, transformer):\n","        super(Translator, self).__init__()\n","        self.transformer = transformer\n","\n","    @staticmethod\n","    def str_to_tokens(s):\n","        return [ord(z)-97+3 for z in s]\n","\n","    @staticmethod\n","    def tokens_to_str(tokens):\n","        return \"\".join([chr(x+94) for x in tokens])\n","\n","    def __call__(self, sentence, max_length=None, pad=False):\n","        # Преобразование строки в тензор токенов\n","        x = torch.tensor(self.str_to_tokens(sentence))\n","        x = torch.cat([torch.tensor([SOS_IDX]), x, torch.tensor([EOS_IDX])]).unsqueeze(0)\n","\n","        # Получение выходов энкодера и маски\n","        encoder_output, mask = self.transformer.encode(x)  # (B, S, E)\n","\n","        if not max_length:\n","            max_length = x.size(1)\n","\n","        outputs = torch.ones((x.size()[0], max_length)).type_as(x).long() * SOS_IDX\n","\n","        for step in range(1, max_length):\n","            y = outputs[:, :step]\n","            probs = self.transformer.decode(y, encoder_output)\n","            output = torch.argmax(probs, dim=-1)\n","            if output[:, -1].detach().numpy() in (EOS_IDX, SOS_IDX):\n","                break\n","            outputs[:, step] = output[:, -1]\n","\n","        return self.tokens_to_str(outputs[0])\n","\n","translator = Translator(model)\n","\n","# Пример использования\n","sentence = \"\" # Напишите любое слово\n","translation = translator(sentence)\n","print(f\"Original: {sentence}\")\n","print(f\"Translated: {translation}\")"]},{"cell_type":"markdown","metadata":{"id":"c6XPzlAxKPYx"},"source":["И снова отрисуем тепловую карту первого блока из декодера."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d3VR00pXa2XQ"},"outputs":[],"source":["fig = plt.figure()\n","images = # Ваш код здесь\n","\n","fig, ax = plt.subplots(1,1, figsize=(10., 10.))\n","\n","ax.set_yticks(range(len(translation)))\n","ax.set_xticks(range(len(sentence)))\n","\n","ax.xaxis.set_label_position('top')\n","\n","ax.set_xticklabels(iter(sentence))\n","ax.set_yticklabels([f\"step {i}\" for i in range(len(translation))])\n","ax.imshow(images)"]},{"cell_type":"markdown","metadata":{"id":"u9kyfOzgKUJL"},"source":["Какой вывод можно сделать?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oW3P-L58zc3y"},"outputs":[],"source":["Ваш ответ = \"\" # @param {type:\"string\"}"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[{"file_id":"1uSTCRkSjBeQhbpc6x0UIwcLQ5ZrsrsS3","timestamp":1720784171450}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}